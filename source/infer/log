faster_rcnn_r50_caffe_fpn_mstrain_1x_ddsm
Get best checkpoint from /home/hqvo2/Projects/Breast_Cancer/experiments/mmdet_processed_data/faster_rcnn_r50_caffe_fpn_mstrain_1x_ddsm
FasterRCNN(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (rpn_head): RPNHead(
    (loss_cls): CrossEntropyLoss()
    (loss_bbox): L1Loss()
    (rpn_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (rpn_cls): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
    (rpn_reg): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
  )
  (roi_head): StandardRoIHead(
    (bbox_roi_extractor): SingleRoIExtractor(
      (roi_layers): ModuleList(
        (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
      )
    )
    (bbox_head): Shared2FCBBoxHead(
      (loss_cls): CrossEntropyLoss()
      (loss_bbox): L1Loss()
      (fc_cls): Linear(in_features=1024, out_features=3, bias=True)
      (fc_reg): Linear(in_features=1024, out_features=8, bias=True)
      (shared_convs): ModuleList()
      (shared_fcs): ModuleList(
        (0): Linear(in_features=12544, out_features=1024, bias=True)
        (1): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (cls_convs): ModuleList()
      (cls_fcs): ModuleList()
      (reg_convs): ModuleList()
      (reg_fcs): ModuleList()
      (relu): ReLU(inplace=True)
    )
  )
)
[                                                  ] 0/541, elapsed: 0s, ETA:[                              ] 1/541, 1375.6 task/s, elapsed: 0s, ETA:     0s[                              ] 2/541, 1872.5 task/s, elapsed: 0s, ETA:     0s[                              ] 3/541, 2380.4 task/s, elapsed: 0s, ETA:     0s[                              ] 4/541, 2812.6 task/s, elapsed: 0s, ETA:     0s[                              ] 5/541, 3187.2 task/s, elapsed: 0s, ETA:     0s[                              ] 6/541, 3504.5 task/s, elapsed: 0s, ETA:     0s[                              ] 7/541, 3788.4 task/s, elapsed: 0s, ETA:     0s[                              ] 8/541, 4008.4 task/s, elapsed: 0s, ETA:     0s[                              ] 9/541, 4181.8 task/s, elapsed: 0s, ETA:     0s[                             ] 10/541, 4355.0 task/s, elapsed: 0s, ETA:     0s[                             ] 11/541, 4502.1 task/s, elapsed: 0s, ETA:     0s[                             ] 12/541, 4661.6 task/s, elapsed: 0s, ETA:     0s[                             ] 13/541, 4795.2 task/s, elapsed: 0s, ETA:     0s[                             ] 14/541, 4922.5 task/s, elapsed: 0s, ETA:     0s[                             ] 15/541, 5044.5 task/s, elapsed: 0s, ETA:     0s[                             ] 16/541, 5157.1 task/s, elapsed: 0s, ETA:     0s[                             ] 17/541, 5259.5 task/s, elapsed: 0s, ETA:     0s[                             ] 18/541, 5354.1 task/s, elapsed: 0s, ETA:     0s[>                            ] 19/541, 5441.9 task/s, elapsed: 0s, ETA:     0s[>                            ] 20/541, 5524.6 task/s, elapsed: 0s, ETA:     0s[>                            ] 21/541, 5597.7 task/s, elapsed: 0s, ETA:     0s[>                            ] 22/541, 5669.0 task/s, elapsed: 0s, ETA:     0s[>                            ] 23/541, 5735.0 task/s, elapsed: 0s, ETA:     0s[>                            ] 24/541, 5791.6 task/s, elapsed: 0s, ETA:     0s[>                            ] 25/541, 5850.1 task/s, elapsed: 0s, ETA:     0s[>                            ] 26/541, 5908.1 task/s, elapsed: 0s, ETA:     0s[>                            ] 27/541, 5961.0 task/s, elapsed: 0s, ETA:     0s[>                            ] 28/541, 6011.5 task/s, elapsed: 0s, ETA:     0s[>                            ] 29/541, 6041.3 task/s, elapsed: 0s, ETA:     0s[>                            ] 30/541, 6087.5 task/s, elapsed: 0s, ETA:     0s[>                            ] 31/541, 6127.7 task/s, elapsed: 0s, ETA:     0s[>                            ] 32/541, 6161.9 task/s, elapsed: 0s, ETA:     0s[>                            ] 33/541, 6197.9 task/s, elapsed: 0s, ETA:     0s[>                            ] 34/541, 6235.0 task/s, elapsed: 0s, ETA:     0s[>                            ] 35/541, 6269.0 task/s, elapsed: 0s, ETA:     0s[>                            ] 36/541, 6295.7 task/s, elapsed: 0s, ETA:     0s[>                            ] 37/541, 6324.2 task/s, elapsed: 0s, ETA:     0s[>>                           ] 38/541, 6355.0 task/s, elapsed: 0s, ETA:     0s[>>                           ] 39/541, 6382.3 task/s, elapsed: 0s, ETA:     0s[>>                           ] 40/541, 6410.9 task/s, elapsed: 0s, ETA:     0s[>>                           ] 41/541, 6438.3 task/s, elapsed: 0s, ETA:     0s[>>                           ] 42/541, 6465.6 task/s, elapsed: 0s, ETA:     0s[>>                           ] 43/541, 6488.5 task/s, elapsed: 0s, ETA:     0s[>>                           ] 44/541, 6512.4 task/s, elapsed: 0s, ETA:     0s[>>                           ] 45/541, 6535.9 task/s, elapsed: 0s, ETA:     0s[>>                           ] 46/541, 6558.9 task/s, elapsed: 0s, ETA:     0s[>>                           ] 47/541, 6577.9 task/s, elapsed: 0s, ETA:     0s[>>                           ] 48/541, 6597.8 task/s, elapsed: 0s, ETA:     0s[>>                           ] 49/541, 6618.2 task/s, elapsed: 0s, ETA:     0s[>>                           ] 50/541, 6637.8 task/s, elapsed: 0s, ETA:     0s[>>                           ] 51/541, 6655.3 task/s, elapsed: 0s, ETA:     0s[>>                           ] 52/541, 6666.0 task/s, elapsed: 0s, ETA:     0s[>>                           ] 53/541, 6684.0 task/s, elapsed: 0s, ETA:     0s[>>                           ] 54/541, 6701.8 task/s, elapsed: 0s, ETA:     0s[>>                           ] 55/541, 6716.0 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 56/541, 6723.4 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 57/541, 6727.3 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 58/541, 6732.6 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 59/541, 6736.1 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 60/541, 6661.7 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 61/541, 6515.9 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 62/541, 6381.0 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 63/541, 6262.5 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 64/541, 6212.5 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 65/541, 6231.8 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 66/541, 6250.4 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 67/541, 6265.7 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 68/541, 6282.4 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 69/541, 6300.6 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 70/541, 6317.5 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 71/541, 6333.2 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 72/541, 6349.1 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 73/541, 6365.4 task/s, elapsed: 0s, ETA:     0s[>>>                          ] 74/541, 6381.1 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 75/541, 6392.2 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 76/541, 6406.9 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 77/541, 6420.6 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 78/541, 6432.9 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 79/541, 6440.4 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 80/541, 6454.1 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 81/541, 6467.8 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 82/541, 6481.2 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 83/541, 6489.1 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 84/541, 6501.8 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 85/541, 6514.3 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 86/541, 6525.4 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 87/541, 6536.1 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 88/541, 6548.6 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 89/541, 6561.0 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 90/541, 6570.7 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 91/541, 6578.6 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 92/541, 6589.7 task/s, elapsed: 0s, ETA:     0s[>>>>                         ] 93/541, 6601.0 task/s, elapsed: 0s, ETA:     0s[>>>>>                        ] 94/541, 6611.7 task/s, elapsed: 0s, ETA:     0s[>>>>>                        ] 95/541, 6622.4 task/s, elapsed: 0s, ETA:     0s[>>>>>                        ] 96/541, 6632.9 task/s, elapsed: 0s, ETA:     0s[>>>>>                        ] 97/541, 6643.5 task/s, elapsed: 0s, ETA:     0s[>>>>>                        ] 98/541, 6653.4 task/s, elapsed: 0s, ETA:     0s[>>>>>                        ] 99/541, 6663.4 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 100/541, 6673.1 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 101/541, 6681.5 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 102/541, 6690.2 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 103/541, 6699.6 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 104/541, 6708.8 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 105/541, 6712.4 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 106/541, 6714.0 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 107/541, 6716.8 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 108/541, 6720.7 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 109/541, 6723.0 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 110/541, 6726.7 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 111/541, 6729.7 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 112/541, 6738.6 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 113/541, 6746.9 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 114/541, 6754.9 task/s, elapsed: 0s, ETA:     0s[>>>>>                       ] 115/541, 6762.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 116/541, 6770.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 117/541, 6777.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 118/541, 6785.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 119/541, 6793.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 120/541, 6801.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 121/541, 6806.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 122/541, 6812.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 123/541, 6820.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 124/541, 6827.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 125/541, 6835.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 126/541, 6841.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 127/541, 6848.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 128/541, 6855.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 129/541, 6860.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 130/541, 6867.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 131/541, 6873.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 132/541, 6879.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 133/541, 6886.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 134/541, 6891.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>                      ] 135/541, 6898.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 136/541, 6902.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 137/541, 6908.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 138/541, 6914.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 139/541, 6920.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 140/541, 6926.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 141/541, 6932.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 142/541, 6938.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 143/541, 6944.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 144/541, 6949.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 145/541, 6954.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 146/541, 6959.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 147/541, 6964.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 148/541, 6969.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 149/541, 6974.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 150/541, 6979.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 151/541, 6984.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 152/541, 6989.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 153/541, 6994.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>                     ] 154/541, 6999.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 155/541, 6942.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 156/541, 6881.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 157/541, 6815.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 158/541, 6785.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 159/541, 6786.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 160/541, 6788.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 161/541, 6788.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 162/541, 6789.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 163/541, 6791.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 164/541, 6792.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 165/541, 6793.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 166/541, 6799.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 167/541, 6803.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 168/541, 6809.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 169/541, 6812.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 170/541, 6816.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 171/541, 6821.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 172/541, 6825.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>                    ] 173/541, 6830.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 174/541, 6835.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 175/541, 6840.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 176/541, 6843.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 177/541, 6843.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 178/541, 6845.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 179/541, 6844.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 180/541, 6845.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 181/541, 6850.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 182/541, 6855.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 183/541, 6860.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 184/541, 6863.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 185/541, 6867.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 186/541, 6871.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 187/541, 6875.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 188/541, 6880.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 189/541, 6884.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 190/541, 6888.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 191/541, 6891.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 192/541, 6895.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>                   ] 193/541, 6899.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 194/541, 6904.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 195/541, 6908.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 196/541, 6912.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 197/541, 6917.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 198/541, 6921.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 199/541, 6925.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 200/541, 6929.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 201/541, 6933.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 202/541, 6936.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 203/541, 6940.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 204/541, 6944.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 205/541, 6948.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 206/541, 6952.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 207/541, 6955.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 208/541, 6959.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 209/541, 6920.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 210/541, 6924.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 211/541, 6928.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>                  ] 212/541, 6932.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 213/541, 6934.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 214/541, 6938.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 215/541, 6941.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 216/541, 6945.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 217/541, 6949.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 218/541, 6952.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 219/541, 6956.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 220/541, 6960.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 221/541, 6963.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 222/541, 6967.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 223/541, 6970.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 224/541, 6974.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 225/541, 6977.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 226/541, 6981.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 227/541, 6984.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 228/541, 6988.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 229/541, 6991.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 230/541, 6994.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>                 ] 231/541, 6998.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 232/541, 7001.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 233/541, 7005.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 234/541, 7008.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 235/541, 7012.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 236/541, 7015.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 237/541, 7016.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 238/541, 7019.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 239/541, 7022.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 240/541, 7023.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 241/541, 7026.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 242/541, 7029.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 243/541, 7032.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 244/541, 7034.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 245/541, 7036.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 246/541, 7039.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 247/541, 7042.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 248/541, 7045.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 249/541, 7045.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 250/541, 7049.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>                ] 251/541, 7052.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 252/541, 7054.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 253/541, 7057.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 254/541, 7060.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 255/541, 7063.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 256/541, 7066.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 257/541, 7069.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 258/541, 7071.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 259/541, 7074.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 260/541, 7077.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 261/541, 7080.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 262/541, 7083.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 263/541, 7085.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 264/541, 7088.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 265/541, 7091.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 266/541, 7094.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 267/541, 7096.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 268/541, 7096.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 269/541, 7096.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>               ] 270/541, 7097.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 271/541, 7097.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 272/541, 7094.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 273/541, 7097.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 274/541, 7100.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 275/541, 7102.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 276/541, 7104.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 277/541, 7107.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 278/541, 7110.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 279/541, 7112.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 280/541, 7114.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 281/541, 7117.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 282/541, 7120.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 283/541, 7122.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 284/541, 7124.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 285/541, 7124.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 286/541, 7121.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 287/541, 7121.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 288/541, 7120.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>              ] 289/541, 7123.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 290/541, 7124.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 291/541, 7126.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 292/541, 7129.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 293/541, 7131.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 294/541, 7134.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 295/541, 7134.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 296/541, 7136.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 297/541, 7138.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 298/541, 7140.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 299/541, 7143.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 300/541, 7145.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 301/541, 7147.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 302/541, 7149.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 303/541, 7150.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 304/541, 7152.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 305/541, 7154.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 306/541, 7157.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 307/541, 7159.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 308/541, 7161.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>             ] 309/541, 7163.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 310/541, 7165.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 311/541, 7167.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 312/541, 7169.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 313/541, 7172.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 314/541, 7171.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 315/541, 7170.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 316/541, 7170.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 317/541, 7168.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 318/541, 7169.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 319/541, 7171.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 320/541, 7173.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 321/541, 7174.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 322/541, 7177.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 323/541, 7179.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 324/541, 7180.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 325/541, 7183.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 326/541, 7185.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 327/541, 7187.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>            ] 328/541, 7189.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 329/541, 7191.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 330/541, 7193.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 331/541, 7194.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 332/541, 7196.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 333/541, 7183.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 334/541, 7150.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 335/541, 7120.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 336/541, 7091.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 337/541, 7093.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 338/541, 7093.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 339/541, 7091.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 340/541, 7091.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 341/541, 7091.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 342/541, 7091.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 343/541, 7093.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 344/541, 7095.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 345/541, 7095.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 346/541, 7096.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>           ] 347/541, 7096.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 348/541, 7096.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 349/541, 7096.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 350/541, 7096.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 351/541, 7096.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 352/541, 7097.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 353/541, 7097.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 354/541, 7097.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 355/541, 7097.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 356/541, 7097.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 357/541, 7099.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 358/541, 7102.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 359/541, 7102.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 360/541, 7101.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 361/541, 7101.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 362/541, 7101.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 363/541, 7101.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 364/541, 7101.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 365/541, 7100.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 366/541, 7100.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>          ] 367/541, 7102.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 368/541, 7103.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 369/541, 7105.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 370/541, 7107.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 371/541, 7109.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 372/541, 7111.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 373/541, 7113.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 374/541, 7115.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 375/541, 7116.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 376/541, 7118.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 377/541, 7119.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 378/541, 7121.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 379/541, 7123.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 380/541, 7123.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 381/541, 7125.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 382/541, 7127.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 383/541, 7129.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 384/541, 7131.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 385/541, 7133.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>         ] 386/541, 7135.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 387/541, 7136.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 388/541, 7138.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 389/541, 7140.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 390/541, 7142.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 391/541, 7143.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 392/541, 7145.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 393/541, 7147.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 394/541, 7148.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 395/541, 7150.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 396/541, 7151.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 397/541, 7153.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 398/541, 7154.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 399/541, 7156.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 400/541, 7158.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 401/541, 7159.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 402/541, 7160.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 403/541, 7162.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 404/541, 7164.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>        ] 405/541, 7165.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 406/541, 7167.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 407/541, 7168.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 408/541, 7170.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 409/541, 7171.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 410/541, 7173.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 411/541, 7174.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 412/541, 7176.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 413/541, 7178.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 414/541, 7180.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 415/541, 7181.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 416/541, 7182.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 417/541, 7183.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 418/541, 7182.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 419/541, 7182.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 420/541, 7182.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 421/541, 7182.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 422/541, 7184.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 423/541, 7186.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 424/541, 7187.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>       ] 425/541, 7188.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 426/541, 7190.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 427/541, 7191.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 428/541, 7193.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 429/541, 7195.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 430/541, 7196.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 431/541, 7198.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 432/541, 7197.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 433/541, 7197.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 434/541, 7197.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 435/541, 7196.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 436/541, 7196.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 437/541, 7196.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 438/541, 7198.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 439/541, 7199.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 440/541, 7200.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 441/541, 7202.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 442/541, 7203.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 443/541, 7204.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>      ] 444/541, 7205.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 445/541, 7207.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 446/541, 7208.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 447/541, 7210.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 448/541, 7209.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 449/541, 7210.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 450/541, 7212.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 451/541, 7213.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 452/541, 7215.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 453/541, 7215.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 454/541, 7215.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 455/541, 7215.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 456/541, 7215.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 457/541, 7215.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 458/541, 7217.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 459/541, 7218.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 460/541, 7219.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 461/541, 7220.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 462/541, 7221.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>     ] 463/541, 7223.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 464/541, 7224.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 465/541, 7225.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 466/541, 7227.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 467/541, 7228.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 468/541, 7229.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 469/541, 7230.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 470/541, 7232.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 471/541, 7231.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 472/541, 7231.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 473/541, 7231.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 474/541, 7231.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 475/541, 7229.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 476/541, 7231.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 477/541, 7229.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 478/541, 7229.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 479/541, 7229.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 480/541, 7229.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 481/541, 7230.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 482/541, 7231.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>    ] 483/541, 7232.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 484/541, 7233.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 485/541, 7234.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 486/541, 7235.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 487/541, 7236.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 488/541, 7237.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 489/541, 7238.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 490/541, 7239.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 491/541, 7240.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 492/541, 7241.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 493/541, 7242.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 494/541, 7243.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 495/541, 7243.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 496/541, 7244.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 497/541, 7244.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 498/541, 7243.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 499/541, 7242.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 500/541, 7242.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 501/541, 7242.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>   ] 502/541, 7242.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 503/541, 7242.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 504/541, 7242.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 505/541, 7242.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 506/541, 7242.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 507/541, 7241.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 508/541, 7239.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 509/541, 7239.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 510/541, 7239.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 511/541, 7240.5 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 512/541, 7241.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 513/541, 7242.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 514/541, 7243.2 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 515/541, 7244.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 516/541, 7245.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 517/541, 7247.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 518/541, 7248.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 519/541, 7249.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 520/541, 7249.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>  ] 521/541, 7249.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 522/541, 7248.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 523/541, 7248.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 524/541, 7246.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 525/541, 7238.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 526/541, 7217.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 527/541, 7196.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 528/541, 7179.4 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 529/541, 7177.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 530/541, 7179.1 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 531/541, 7178.0 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 532/541, 7177.8 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 533/541, 7177.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 534/541, 7177.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 535/541, 7178.9 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 536/541, 7180.3 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 537/541, 7179.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 538/541, 7179.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 539/541, 7179.7 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>> ] 540/541, 7179.6 task/s, elapsed: 0s, ETA:     0s[>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 541/541, 7178.3 task/s, elapsed: 0s, ETA:     0s
FasterRCNN(
  (backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (rpn_head): RPNHead(
    (loss_cls): CrossEntropyLoss()
    (loss_bbox): L1Loss()
    (rpn_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (rpn_cls): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
    (rpn_reg): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
  )
  (roi_head): StandardRoIHead(
    (bbox_roi_extractor): SingleRoIExtractor(
      (roi_layers): ModuleList(
        (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
        (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)
      )
    )
    (bbox_head): Shared2FCBBoxHead(
      (loss_cls): CrossEntropyLoss()
      (loss_bbox): L1Loss()
      (fc_cls): Linear(in_features=1024, out_features=3, bias=True)
      (fc_reg): Linear(in_features=1024, out_features=8, bias=True)
      (shared_convs): ModuleList()
      (shared_fcs): ModuleList(
        (0): Linear(in_features=12544, out_features=1024, bias=True)
        (1): Linear(in_features=1024, out_features=1024, bias=True)
      )
      (cls_convs): ModuleList()
      (cls_fcs): ModuleList()
      (reg_convs): ModuleList()
      (reg_fcs): ModuleList()
      (relu): ReLU(inplace=True)
    )
  )
)
